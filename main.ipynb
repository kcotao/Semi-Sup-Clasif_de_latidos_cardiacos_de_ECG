{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b31be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64630e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_semi_supervised.csv\")\n",
    "test_df = pd.read_csv(\"test_semi_supervised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35023, 188), (43779, 188), (43775, 188), (8756, 188))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = train_df.columns[:-1]    # todas menos la última\n",
    "label_col    = train_df.columns[-1]     # última columna\n",
    "test_feature_cols = test_df.columns[1:]  # todas menos 'id'\n",
    "\n",
    "\n",
    "# Separar labeled y unlabeled\n",
    "df_labeled   = train_df[train_df[label_col].notna()].copy()\n",
    "df_unlabeled = train_df[train_df[label_col].isna()].copy()\n",
    "\n",
    "# division en training y test\n",
    "train_df, val_df = train_test_split(\n",
    "    df_labeled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_labeled[label_col]   # estratificación por clase\n",
    ")\n",
    "\n",
    "# Convertir label a int (solo los labeled)\n",
    "df_labeled[label_col] = df_labeled[label_col].astype(int)\n",
    "\n",
    "train_df.shape, df_labeled.shape, df_unlabeled.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77bf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ECGSupervisedDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, label_col):\n",
    "        # Guardamos los datos ya como numpy para que __getitem__ sea rápido\n",
    "        self.X = df[feature_cols].to_numpy(dtype=np.float32)\n",
    "        self.y = df[label_col].to_numpy(dtype=np.int64)  # para CrossEntropyLoss\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.X[idx])              # tensor float32\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)  # tensor long (clase)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101a6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGUnlabeledDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols):\n",
    "        self.X = df[feature_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.X[idx])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4188ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGTestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        # primera columna = id\n",
    "        self.ids = df.iloc[:, 0].to_numpy()\n",
    "\n",
    "        # features = todas excepto id y label\n",
    "        self.X = df.iloc[:, 1:-1].to_numpy(dtype=np.float32)\n",
    "\n",
    "        # revisar si la última columna es el label\n",
    "        # si contiene solo 0,1,2,3,4 asumimos labels reales\n",
    "        last_col = df.iloc[:, -1]\n",
    "\n",
    "        if last_col.dropna().isin([0,1,2,3,4]).all():\n",
    "            self.has_labels = True\n",
    "            self.y = last_col.to_numpy(dtype=np.int64)\n",
    "        else:\n",
    "            self.has_labels = False\n",
    "            self.y = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x  = torch.from_numpy(self.X[idx])\n",
    "        id_ = int(self.ids[idx])\n",
    "\n",
    "        if self.has_labels:\n",
    "            y = int(self.y[idx])\n",
    "            return x, id_, y\n",
    "\n",
    "        return x, id_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_dataset      = ECGSupervisedDataset(df_labeled, feature_cols, label_col)\n",
    "val_dataset   = ECGSupervisedDataset(val_df, feature_cols, label_col)\n",
    "unlabeled_dataset  = ECGUnlabeledDataset(df_unlabeled, feature_cols)\n",
    "test_dataset       = ECGTestDataset(test_df)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 256  # ajustar según GPU/CPU\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "unlabeled_loader = DataLoader(\n",
    "    unlabeled_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34e5d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e0a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ECGBetterCNN(nn.Module):\n",
    "    def __init__(self, input_length=187, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),   # 187 -> ~93\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),   # ~93 -> ~46\n",
    "        )\n",
    "\n",
    "        # tamaño después de las pools: 187 // 4 ≈ 46\n",
    "        conv_out_len = input_length // 4\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * conv_out_len, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, 187) -> (batch, 1, 187)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.features(x)          # (batch, 128, L')\n",
    "        x = x.flatten(1)              # (batch, 128*L')\n",
    "        x = self.classifier(x)        # (batch, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "num_features = len(feature_cols)   # debería ser 187\n",
    "num_classes  = train_df[label_col].nunique()\n",
    "\n",
    "model = ECGBetterCNN(input_length=num_features, num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d7ad42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts:\n",
      " 187\n",
      "0.0    28989\n",
      "1.0      889\n",
      "2.0     2315\n",
      "3.0      257\n",
      "4.0     2573\n",
      "Name: count, dtype: int64\n",
      "class weights:\n",
      " [ 0.24162958  7.8791901   3.02574514 27.25525292  2.72234745]\n"
     ]
    }
   ],
   "source": [
    "class_counts = train_df[label_col].value_counts().sort_index()\n",
    "num_samples = class_counts.sum()\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "weights_np = num_samples / (num_classes * class_counts.to_numpy())\n",
    "print(\"class counts:\\n\", class_counts)\n",
    "print(\"class weights:\\n\", weights_np)\n",
    "\n",
    "class_weights_tensor = torch.tensor(weights_np, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b01909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == yb).sum().item()\n",
    "        total_samples += xb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc  = total_correct / total_samples\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == yb).sum().item()\n",
    "        total_samples += xb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc  = total_correct / total_samples\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08056fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 187]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = next(iter(train_loader))\n",
    "print(xb.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bcb1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.5655 acc=0.7320 | val_loss=0.3915 acc=0.9038\n",
      "Epoch 02 | train_loss=0.3560 acc=0.8416 | val_loss=0.3054 acc=0.8199\n",
      "Epoch 03 | train_loss=0.2920 acc=0.8645 | val_loss=0.2148 acc=0.9467\n",
      "Epoch 04 | train_loss=0.2263 acc=0.8882 | val_loss=0.1745 acc=0.8926\n",
      "Epoch 05 | train_loss=0.2087 acc=0.8965 | val_loss=0.1631 acc=0.9487\n",
      "Epoch 06 | train_loss=0.1872 acc=0.9022 | val_loss=0.1189 acc=0.9577\n",
      "Epoch 07 | train_loss=0.1680 acc=0.9146 | val_loss=0.1131 acc=0.9195\n",
      "Epoch 08 | train_loss=0.1539 acc=0.9189 | val_loss=0.0924 acc=0.9560\n",
      "Epoch 09 | train_loss=0.1152 acc=0.9371 | val_loss=0.0804 acc=0.9547\n",
      "Epoch 10 | train_loss=0.1059 acc=0.9373 | val_loss=0.0779 acc=0.9717\n",
      "Epoch 11 | train_loss=0.1029 acc=0.9418 | val_loss=0.0679 acc=0.9721\n",
      "Epoch 12 | train_loss=0.0873 acc=0.9493 | val_loss=0.0521 acc=0.9632\n",
      "Epoch 13 | train_loss=0.0763 acc=0.9533 | val_loss=0.0556 acc=0.9684\n",
      "Epoch 14 | train_loss=0.0915 acc=0.9512 | val_loss=0.0460 acc=0.9643\n",
      "Epoch 15 | train_loss=0.0698 acc=0.9589 | val_loss=0.0479 acc=0.9676\n",
      "Epoch 16 | train_loss=0.0701 acc=0.9600 | val_loss=0.0424 acc=0.9639\n",
      "Epoch 17 | train_loss=0.0658 acc=0.9635 | val_loss=0.0382 acc=0.9782\n",
      "Epoch 18 | train_loss=0.0583 acc=0.9653 | val_loss=0.0468 acc=0.9596\n",
      "Epoch 19 | train_loss=0.0626 acc=0.9618 | val_loss=0.0347 acc=0.9633\n",
      "Epoch 20 | train_loss=0.0486 acc=0.9703 | val_loss=0.0312 acc=0.9688\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc     = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
    "          f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32bd8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_pseudo_labels(model, unlabeled_loader, device, threshold=0.9):\n",
    "    model.eval()\n",
    "    all_max_probs = []\n",
    "    all_preds = []\n",
    "\n",
    "    for xb in unlabeled_loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        max_probs, preds = probs.max(dim=1)\n",
    "\n",
    "        all_max_probs.append(max_probs.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "\n",
    "    all_max_probs = torch.cat(all_max_probs).numpy()\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "\n",
    "    mask = all_max_probs >= threshold\n",
    "\n",
    "    print(f\"Total unlabeled: {len(all_max_probs)}\")\n",
    "    print(f\"Pseudo-labels con conf >= {threshold}: {mask.sum()}\")\n",
    "\n",
    "    return all_preds, all_max_probs, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76df7ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unlabeled: 43775\n",
      "Pseudo-labels con conf >= 0.9: 40392\n"
     ]
    }
   ],
   "source": [
    "all_preds, all_max_probs, mask = generate_pseudo_labels(\n",
    "    model, unlabeled_loader, device, threshold=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfaf594e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pseudo shape: (40392, 189)\n",
      "Antes self-training: (35023, 189)\n",
      "Después self-training: (75415, 189)\n"
     ]
    }
   ],
   "source": [
    "# Filas confiables del unlabeled\n",
    "df_pseudo = df_unlabeled.loc[mask].copy()\n",
    "df_pseudo[label_col] = all_preds[mask]  # asignamos la clase predicha\n",
    "df_pseudo[\"is_pseudo\"] = True           # opcional, para debug\n",
    "\n",
    "print(\"df_pseudo shape:\", df_pseudo.shape)\n",
    "\n",
    "# Marcamos los reales (opcional también)\n",
    "train_df[\"is_pseudo\"] = False\n",
    "\n",
    "# Nuevo train con reales + pseudo\n",
    "train_df_self = pd.concat([train_df, df_pseudo], ignore_index=True)\n",
    "print(\"Antes self-training:\", train_df.shape)\n",
    "print(\"Después self-training:\", train_df_self.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "221f20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled_remaining = df_unlabeled.loc[~mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09a2d148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights (self-training): [ 0.24302333  7.92590646  2.92760093 26.98211091  2.62907443]\n"
     ]
    }
   ],
   "source": [
    "class_counts = train_df_self[label_col].value_counts().sort_index()\n",
    "num_samples = class_counts.sum()\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "weights = num_samples / (num_classes * class_counts.to_numpy())\n",
    "print(\"class weights (self-training):\", weights)\n",
    "\n",
    "class_weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SELF] Epoch 01 | train_loss=0.0510 acc=0.9698 | val_loss=0.0473 acc=0.9790\n",
      "[SELF] Epoch 02 | train_loss=0.0512 acc=0.9709 | val_loss=0.0334 acc=0.9786\n",
      "[SELF] Epoch 03 | train_loss=0.0721 acc=0.9639 | val_loss=0.0379 acc=0.9744\n",
      "[SELF] Epoch 04 | train_loss=0.0583 acc=0.9695 | val_loss=0.0270 acc=0.9880\n",
      "[SELF] Epoch 05 | train_loss=0.0615 acc=0.9698 | val_loss=0.0300 acc=0.9794\n",
      "[SELF] Epoch 06 | train_loss=0.0525 acc=0.9726 | val_loss=0.0299 acc=0.9733\n",
      "[SELF] Epoch 07 | train_loss=0.0391 acc=0.9772 | val_loss=0.0239 acc=0.9863\n",
      "[SELF] Epoch 08 | train_loss=0.0313 acc=0.9813 | val_loss=0.0195 acc=0.9892\n",
      "[SELF] Epoch 09 | train_loss=0.0344 acc=0.9811 | val_loss=0.0349 acc=0.9823\n",
      "[SELF] Epoch 10 | train_loss=0.0353 acc=0.9803 | val_loss=0.0208 acc=0.9861\n"
     ]
    }
   ],
   "source": [
    "num_epochs_self = 10\n",
    "\n",
    "for epoch in range(1, num_epochs_self + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc     = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"[SELF] Epoch {epoch:02d} | \"\n",
    "          f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
    "          f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f48405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "all_ids = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # soportar (x, id) o (x, id, y_real)\n",
    "        if len(batch) == 3:\n",
    "            xb, ids, _ = batch\n",
    "        else:\n",
    "            xb, ids = batch\n",
    "\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_ids.append(ids.numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "all_ids   = np.concatenate(all_ids)\n",
    "all_preds = np.concatenate(all_preds).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a1d52dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Label\n",
      "0   0      0\n",
      "1   1      0\n",
      "2   2      0\n",
      "3   3      0\n",
      "4   4      0\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"Id\": np.arange(len(all_preds)),   # 0,1,2,...,N-1\n",
    "    \"Label\": all_preds\n",
    "})\n",
    "\n",
    "print(submission.head())\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
